{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Steps:\n\n- Load data and visualize a sample of them\n- Check for distribution across classes\n\n- Give ERM/IRM a shot to improve the performance","metadata":{}},{"cell_type":"code","source":"# Run following commands if running on local\n# !pip install kaggle\n\n# Download kaggle.json from kaggle website under profile->new API section\n# !kaggle competitions download -c plant-seedlings-classification\n# !unzip -q plant-seedlings-classification.zip","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.013147Z","iopub.execute_input":"2023-04-06T22:48:21.013768Z","iopub.status.idle":"2023-04-06T22:48:21.018825Z","shell.execute_reply.started":"2023-04-06T22:48:21.013731Z","shell.execute_reply":"2023-04-06T22:48:21.017218Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.chdir('/kaggle/input/plant-seedlings-classification/')","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.021586Z","iopub.execute_input":"2023-04-06T22:48:21.021951Z","iopub.status.idle":"2023-04-06T22:48:21.032437Z","shell.execute_reply.started":"2023-04-06T22:48:21.021915Z","shell.execute_reply":"2023-04-06T22:48:21.031057Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Folder structure\n# Training data\n# contains images in 12 folders, each folder contains images of a single class\n# Test data\n# contains all images in a single folder\n\n# Load the data\nfrom torchvision import datasets, transforms\nfrom transformers import AutoImageProcessor\n\nimage_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\nsize = (\n    (image_processor.size[\"shortest_edge\"], image_processor.size[\"shortest_edge\"])\n    if \"shortest_edge\" in image_processor.size\n    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n)\n\ntransforms = transforms.Compose([\n    # transforms.Resize((256, 256)),\n    transforms.Resize(size),\n    # RandomResizedCrop being used here --> https://huggingface.co/docs/transformers/main/en/tasks/image_classification\n    transforms.RandomRotation(360),\n    transforms.RandomResizedCrop(size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std),\n])\n\ndataset = datasets.ImageFolder('./train', transform=transforms)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.034045Z","iopub.execute_input":"2023-04-06T22:48:21.034716Z","iopub.status.idle":"2023-04-06T22:48:21.466060Z","shell.execute_reply.started":"2023-04-06T22:48:21.034673Z","shell.execute_reply":"2023-04-06T22:48:21.464595Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Class Distribution","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:43:19.981148Z","iopub.execute_input":"2023-04-05T00:43:19.982073Z","iopub.status.idle":"2023-04-05T00:43:19.987338Z","shell.execute_reply.started":"2023-04-05T00:43:19.982023Z","shell.execute_reply":"2023-04-05T00:43:19.985893Z"}}},{"cell_type":"code","source":"# # Plot class distribution\n# from collections import Counter\n# import matplotlib.pyplot as plt\n\n# distribution = dict(Counter(dataset.targets))\n\n# # Plot class distribution histogram\n# plt.bar(list(map(lambda x: dataset.classes[x], distribution.keys())), distribution.values())\n# plt.xticks(rotation=90)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.469552Z","iopub.execute_input":"2023-04-06T22:48:21.469894Z","iopub.status.idle":"2023-04-06T22:48:21.475316Z","shell.execute_reply.started":"2023-04-06T22:48:21.469863Z","shell.execute_reply":"2023-04-06T22:48:21.473911Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Sampling imbalance classes","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:43:46.337206Z","iopub.execute_input":"2023-04-05T00:43:46.338478Z","iopub.status.idle":"2023-04-05T00:43:46.342784Z","shell.execute_reply.started":"2023-04-05T00:43:46.338426Z","shell.execute_reply":"2023-04-05T00:43:46.341565Z"}}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport numpy as np\nfrom torch.utils.data.sampler import WeightedRandomSampler\n\ndef sampler(indices):\n    labels = [dataset.targets[x] for x in indices]\n    print(f'label length: {len(labels)}')\n    distribution = dict(Counter(labels))\n    class_weights = {k: 1/v for k, v in distribution.items()}\n\n    samples_weight = np.array([class_weights[t] for t in labels])\n    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n    return sampler","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.478560Z","iopub.execute_input":"2023-04-06T22:48:21.479638Z","iopub.status.idle":"2023-04-06T22:48:21.486843Z","shell.execute_reply.started":"2023-04-06T22:48:21.479609Z","shell.execute_reply":"2023-04-06T22:48:21.485860Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torch.utils.data import Subset\nfrom collections import Counter\n\n# Split validation data from training data\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nnp.random.shuffle(indices) # shuffle the dataset before splitting into train and val\nprint(f'dataset_size: {dataset_size}')\n\nsplit = int(np.floor(0.8 * dataset_size))\ntrain_indices, val_indices = indices[:split], indices[split:]\n\n# \nBATCH_SIZE = 24\n\ntrain = DataLoader(Subset(dataset, train_indices), sampler=sampler(train_indices), batch_size=BATCH_SIZE)\nval = DataLoader(Subset(dataset, val_indices), sampler=sampler(val_indices), batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.487881Z","iopub.execute_input":"2023-04-06T22:48:21.488798Z","iopub.status.idle":"2023-04-06T22:48:21.507589Z","shell.execute_reply.started":"2023-04-06T22:48:21.488765Z","shell.execute_reply":"2023-04-06T22:48:21.506633Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"dataset_size: 4750\nlabel length: 3800\nlabel length: 950\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Visualize distribution after sampling","metadata":{}},{"cell_type":"code","source":"# # Plot class distribution histogram for training data\n# class_counts = [0]*len(dataset.classes)\n\n# for i, (_, label) in enumerate(train):\n#     for l in label:\n#         class_counts[l] += 1\n\n# # Plot class distribution histogram\n# plt.bar(dataset.classes, class_counts)\n# plt.xticks(rotation=90)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.508891Z","iopub.execute_input":"2023-04-06T22:48:21.509685Z","iopub.status.idle":"2023-04-06T22:48:21.518805Z","shell.execute_reply.started":"2023-04-06T22:48:21.509633Z","shell.execute_reply":"2023-04-06T22:48:21.518028Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# # Plot class distribution histogram for validation data\n# class_counts = [0]*len(dataset.classes)\n\n# for i, (_, label) in enumerate(val):\n#     for l in label:\n#         class_counts[l] += 1\n\n# # Plot class distribution histogram\n# plt.bar(dataset.classes, class_counts)\n# plt.xticks(rotation=90)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.520071Z","iopub.execute_input":"2023-04-06T22:48:21.521545Z","iopub.status.idle":"2023-04-06T22:48:21.529746Z","shell.execute_reply.started":"2023-04-06T22:48:21.521430Z","shell.execute_reply":"2023-04-06T22:48:21.528574Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Visualize images","metadata":{}},{"cell_type":"code","source":"# def visualizeBatch(batch, classes=None):\n#     # sample 8 indexes from BATCH_SIZE\n#     indexes = np.random.choice(BATCH_SIZE, 8, replace=False)\n#     for i, j in enumerate(indexes):\n#         image, idx = batch[0][j], batch[1][j]\n        \n#         ax = plt.subplot(2, 4, i + 1)\n#         image = image.cpu().numpy()\n#         image = image.transpose((1, 2, 0))\n#         image = (255.0 * image).astype('uint8')\n        \n#         plt.imshow(image)\n#         if classes is not None:\n#             plt.title(classes[idx])\n#         plt.axis('off')\n    \n#     plt.tight_layout()\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.531281Z","iopub.execute_input":"2023-04-06T22:48:21.531866Z","iopub.status.idle":"2023-04-06T22:48:21.541245Z","shell.execute_reply.started":"2023-04-06T22:48:21.531835Z","shell.execute_reply":"2023-04-06T22:48:21.539694Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# trainBatch = next(iter(train))\n# visualizeBatch(trainBatch, dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.542888Z","iopub.execute_input":"2023-04-06T22:48:21.543555Z","iopub.status.idle":"2023-04-06T22:48:21.557809Z","shell.execute_reply.started":"2023-04-06T22:48:21.543513Z","shell.execute_reply":"2023-04-06T22:48:21.556913Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# testBatch = next(iter(test))\n# visualizeBatch(testBatch)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.559568Z","iopub.execute_input":"2023-04-06T22:48:21.560649Z","iopub.status.idle":"2023-04-06T22:48:21.570168Z","shell.execute_reply.started":"2023-04-06T22:48:21.560606Z","shell.execute_reply":"2023-04-06T22:48:21.569208Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### FineTuning resnet-50","metadata":{}},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else \n                      'mps' if torch.backends.mps.is_built() else \n                      'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.571370Z","iopub.execute_input":"2023-04-06T22:48:21.571920Z","iopub.status.idle":"2023-04-06T22:48:21.583207Z","shell.execute_reply.started":"2023-04-06T22:48:21.571885Z","shell.execute_reply":"2023-04-06T22:48:21.582244Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from transformers import ResNetForImageClassification\n\nmodel = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\").to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:21.584640Z","iopub.execute_input":"2023-04-06T22:48:21.585513Z","iopub.status.idle":"2023-04-06T22:48:22.078860Z","shell.execute_reply.started":"2023-04-06T22:48:21.585401Z","shell.execute_reply":"2023-04-06T22:48:22.077426Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import sys\n\n# If true passed in sys argv, then load the model from checkpoint\nif len(sys.argv) > 1 and sys.argv[1] == 'True':\n    model.load_state_dict(torch.load('model.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:10:26.238774Z","iopub.execute_input":"2023-04-06T23:10:26.239180Z","iopub.status.idle":"2023-04-06T23:10:26.245353Z","shell.execute_reply.started":"2023-04-06T23:10:26.239143Z","shell.execute_reply":"2023-04-06T23:10:26.244364Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# define trainingloop\ndef train_loop(model, train, val, optimizer, loss_fn, epochs=10):\n    pred_cm = torch.empty(0)\n    label_cm = torch.empty(0)\n    best_val_acc = 0\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        total_correct = 0\n        loops = 0\n        for i, (image, label) in enumerate(tqdm(train)):\n            image = image.to(device)\n            label = label.to(device)\n            \n            optimizer.zero_grad()\n            output = model(image, labels=label)\n            loss = output.loss\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            loops += 1\n            predicted = output.logits.argmax(-1)\n            total_correct += (predicted == label).sum().item()\n        \n        print(f'Epoch: {epoch}, Training Loss: {total_loss/loops:.2f}, Training Accuracy: {(total_correct/(loops*BATCH_SIZE))*100:.2f}%')\n        \n        model.eval()\n        with torch.no_grad():\n            total_loss = 0\n            total_correct = 0\n            loops = 0\n            for i, (image, label) in enumerate(tqdm(val)):\n                image = image.to(device)\n                label = label.to(device)\n                \n                output = model(image, labels=label)\n                loss = output.loss\n                \n                total_loss += loss.item()\n                loops += 1\n                predicted = output.logits.argmax(-1)\n                total_correct += (predicted == label).sum().item()\n                \n                # store predicted and label for confusion matrix\n                pred_cm = torch.cat((pred_cm, predicted.cpu()), 0)\n                label_cm = torch.cat((label_cm, label.cpu()), 0)\n                \n            print(f'Epoch: {epoch}, Validation Loss: {total_loss/loops:.2f}, Validation Accuracy: {(total_correct/(loops*BATCH_SIZE))*100:.2f}%')\n            \n            # Save model if validation accuracy is better than previous best\n            if (total_correct/(loops*BATCH_SIZE))*100 > best_val_acc:\n                best_val_acc = (total_correct/(loops*BATCH_SIZE))*100\n                torch.save(model.state_dict(), 'best_model.pt')\n                print(f'Best model saved with validation accuracy: {best_val_acc:.2f}%')\n    \n    return model, pred_cm, label_cm","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:22.083410Z","iopub.execute_input":"2023-04-06T22:48:22.084327Z","iopub.status.idle":"2023-04-06T22:48:22.097853Z","shell.execute_reply.started":"2023-04-06T22:48:22.084240Z","shell.execute_reply":"2023-04-06T22:48:22.096486Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"epoch = 1\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\ncriteria = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:22.099550Z","iopub.execute_input":"2023-04-06T22:48:22.099907Z","iopub.status.idle":"2023-04-06T22:48:22.117095Z","shell.execute_reply.started":"2023-04-06T22:48:22.099872Z","shell.execute_reply":"2023-04-06T22:48:22.115715Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model, pred_cm, label_cm = train_loop(model, train, val, optimizer, criteria, epochs=epoch)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:48:22.118900Z","iopub.execute_input":"2023-04-06T22:48:22.119310Z","iopub.status.idle":"2023-04-06T22:56:55.063613Z","shell.execute_reply.started":"2023-04-06T22:48:22.119274Z","shell.execute_reply":"2023-04-06T22:56:55.062389Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":" 57%|█████▋    | 90/159 [08:32<06:33,  5.70s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/661376873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/967038869.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, train, val, optimizer, loss_fn, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Confusion matrix\nconf_mat=confusion_matrix(pred_cm.numpy(), label_cm.numpy())\nprint(conf_mat)\n\n# Per-class accuracy\nclass_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\nprint(class_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:10:53.811826Z","iopub.execute_input":"2023-04-06T23:10:53.812178Z","iopub.status.idle":"2023-04-06T23:10:54.416022Z","shell.execute_reply.started":"2023-04-06T23:10:53.812147Z","shell.execute_reply":"2023-04-06T23:10:54.414136Z"},"trusted":true},"execution_count":34,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1132738082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconf_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_cm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_cm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pred_cm' is not defined"],"ename":"NameError","evalue":"name 'pred_cm' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import os, glob\nfrom PIL import Image\nimport pandas as pd\nfrom torchvision import transforms\n\ntransforms = transforms.Compose([\n    # transforms.Resize((256, 256)),\n    transforms.Resize(size),\n    # RandomResizedCrop being used here --> https://huggingface.co/docs/transformers/main/en/tasks/image_classification\n    transforms.ToTensor(),\n    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std),\n])\n\n# create empty dataframe\ndf = pd.DataFrame(columns=['file', 'species'])\n\n# Run model over test data\nfor file_name in tqdm(glob.glob(os.path.join('./test', '*.png'))):\n    image = transforms(Image.open(file_name)).to(device)\n    output = model(image.unsqueeze(0))\n    predicted = output.logits.argmax(-1).item()\n    \n    # append to dataframe\n    df = df.append({'file': file_name.split('/')[-1], 'species': dataset.classes[predicted]}, ignore_index=True)\n\n# Save file to csv\ndf.to_csv('../../working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T22:56:55.066284Z","iopub.status.idle":"2023-04-06T22:56:55.066613Z","shell.execute_reply.started":"2023-04-06T22:56:55.066456Z","shell.execute_reply":"2023-04-06T22:56:55.066475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}